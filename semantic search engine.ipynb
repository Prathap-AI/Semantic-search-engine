{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4930430f-8682-41d6-b1ed-2052fef0518a",
   "metadata": {},
   "source": [
    "# Build a semantic search engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa30c9-6117-4234-8ad4-87f9c6aed6f1",
   "metadata": {},
   "source": [
    "In this model build with LangChain's document loader, embedding, and vector store abstractions. These abstractions are designed to support retrieval of data-- from (vector) databases and other sources-- for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of retrieval-augmented generation, or RAG (see our RAG tutorial here).\n",
    "\n",
    "Here we will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a06ca-c739-439e-979c-30571faa19d2",
   "metadata": {},
   "source": [
    "### Concepts\n",
    "This guide focuses on retrieval of text data. We will cover the following concepts:\n",
    "\n",
    "Documents and document loaders;\n",
    "Text splitters;\n",
    "Embeddings;\n",
    "Vector stores and retrievers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a160f42-58bc-4e7c-bf58-1b269aa62c23",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e951f-b37c-4526-bdc7-61085e48f109",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ee2765-f539-4847-935d-bda38f10f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\prath\\miniconda3\\lib\\site-packages (0.3.29)\n",
      "Requirement already satisfied: pypdf in c:\\users\\prath\\miniconda3\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (0.4.30)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4067597-1aea-40f2-b35f-42c2db12e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6bf6e0-7a01-4fd6-b148-d77fe108e900",
   "metadata": {},
   "source": [
    "### Documents and Document Loaders\n",
    "LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata. It has three attributes:\n",
    "\n",
    "page_content: a string representing the content;\\\n",
    "metadata: a dict containing arbitrary metadata;\\\n",
    "id: (optional) a string identifier for the document.\\\n",
    "The metadata attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual Document object often represents a chunk of a larger document.\n",
    "\n",
    "We can generate sample documents when desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fd35f3-4484-4016-8084-e0f7b910fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af49c08-545c-4dcc-a2f0-3bbfb9167b5c",
   "metadata": {},
   "source": [
    "However, the LangChain ecosystem implements document loaders that integrate with hundreds of common sources. This makes it easy to incorporate data from these sources into your AI application.\n",
    "\n",
    "### Loading documents\n",
    "\n",
    "Let's load a PDF into a sequence of Document objects. There is a sample PDF in the LangChain repo here -- a 10-k filing for Nike from 2023. We can consult the LangChain documentation for available PDF document loaders. Let's select PyPDFLoader, which is fairly lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ae4edf-29ad-4f3a-90ed-a2812debee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"D:\\Portfolio\\Project\\Langchain\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b8cfb-81ee-42ca-a3b9-e8609d512749",
   "metadata": {},
   "source": [
    "PyPDFLoader loads one Document object per PDF page. For each, we can easily access:\n",
    "\n",
    "The string content of the page;\n",
    "Metadata containing the file name and page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0801894c-47a3-4314-93dc-065a8d0f8276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our DE&I focus extends beyond our workforce and includes our communities, which we support in a number of ways. We have \n",
      "committed to investments that aim to address racial inequality and improve diversity and representation in our communities. We \n",
      "also are leveraging our global scale to accelerate business diversity, including investing in business training programs for women \n",
      "and increasing the proportion of services supplied by minority-owned businesses.\n",
      "COMPENSATION AND BENEFITS \n",
      "NIKE's tota\n",
      "\n",
      "{'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'creator': 'Workiva', 'creationdate': '2023-07-20T22:09:22+00:00', 'author': 'anonymous', 'moddate': '2023-07-26T15:13:52+08:00', 'title': 'Nike 2023 Proxy', 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'total_pages': 106, 'page': 10, 'page_label': '11'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{docs[10].page_content[:500]}\\n\")\n",
    "print(docs[10].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f6529-0372-48c4-a862-c567c259eebb",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "For both information retrieval and downstream question-answering purposes, a page may be too coarse a representation. Our goal in the end will be to retrieve Document objects that answer an input query, and further splitting our PDF will help ensure that the meanings of relevant portions of the document are not \"washed out\" by surrounding text.\n",
    "\n",
    "We can use text splitters for this purpose. Here we will use a simple text splitter that partitions based on characters. We will split our documents into chunks of 1000 characters with 200 characters of overlap between chunks. The overlap helps mitigate the possibility of separating a statement from important context related to it. We use the RecursiveCharacterTextSplitter, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "We set add_start_index=True so that the character index where each split Document starts within the initial Document is preserved as metadata attribute “start_index”.\n",
    "\n",
    "See this guide for more detail about working with PDFs, including how to extract text from specific sections and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb66606d-3cdb-4dd1-8845-db3969c5ada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df9bb1-4e78-444c-89d9-e92bf7ff941a",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "Vector search is a common way to store and search over unstructured data (such as unstructured text). The idea is to store numeric vectors that are associated with the text. Given a query, we can embed it as a vector of the same dimension and use vector similarity metrics (such as cosine similarity) to identify related text.\n",
    "\n",
    "LangChain supports embeddings from dozens of providers. These models specify how text should be converted into a numeric vector. Let's select a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "185df88a-23b8-4391-aad2-25238164e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\prath\\miniconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-huggingface) (0.3.76)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-huggingface) (0.35.3)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prath\\miniconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "508708b9-a469-434f-b848-d781e48a9e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.8.0-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prath\\miniconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/12.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading torch-2.8.0-cp310-cp310-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 0.0/241.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 3.9/241.4 MB 18.1 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 8.7/241.4 MB 20.7 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 14.2/241.4 MB 22.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 20.4/241.4 MB 24.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 28.8/241.4 MB 27.7 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 34.9/241.4 MB 28.0 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 43.3/241.4 MB 29.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 50.9/241.4 MB 30.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 57.9/241.4 MB 31.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 62.9/241.4 MB 30.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 71.0/241.4 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 79.2/241.4 MB 31.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 85.7/241.4 MB 32.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 92.3/241.4 MB 31.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 97.3/241.4 MB 31.4 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 103.3/241.4 MB 31.1 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 114.0/241.4 MB 32.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 126.6/241.4 MB 34.0 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 136.8/241.4 MB 34.8 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 143.9/241.4 MB 34.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 151.0/241.4 MB 34.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 157.0/241.4 MB 34.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 166.2/241.4 MB 34.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 178.8/241.4 MB 35.9 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 185.9/241.4 MB 35.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 194.0/241.4 MB 35.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 200.3/241.4 MB 35.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 205.8/241.4 MB 35.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 213.6/241.4 MB 35.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 222.0/241.4 MB 35.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 231.7/241.4 MB 36.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.4 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.4 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.4/241.4 MB 34.1 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   -------------------------------------- - 8.7/8.9 MB 44.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 36.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, safetensors, networkx, joblib, torch, scikit-learn, transformers, sentence-transformers\n",
      "\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ---- ----------------------------------- 1/9 [scipy]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ------------- -------------------------- 3/9 [networkx]\n",
      "   ----------------- ---------------------- 4/9 [joblib]\n",
      "   ----------------- ---------------------- 4/9 [joblib]\n",
      "   ----------------- ---------------------- 4/9 [joblib]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   ---------------------- ----------------- 5/9 [torch]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   -------------------------- ------------- 6/9 [scikit-learn]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ------------------------------- -------- 7/9 [transformers]\n",
      "   ----------------------------------- ---- 8/9 [sentence-transformers]\n",
      "   ----------------------------------- ---- 8/9 [sentence-transformers]\n",
      "   ----------------------------------- ---- 8/9 [sentence-transformers]\n",
      "   ----------------------------------- ---- 8/9 [sentence-transformers]\n",
      "   ---------------------------------------- 9/9 [sentence-transformers]\n",
      "\n",
      "Successfully installed joblib-1.5.2 networkx-3.4.2 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.15.3 sentence-transformers-5.1.1 threadpoolctl-3.6.0 torch-2.8.0 transformers-4.57.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "745458cc-b678-4b1c-804e-fa0adbfc7ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prath\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\prath\\miniconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prath\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8ad23ef-1ae5-454c-be66-d4682fd3bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 768\n",
      "\n",
      "[0.00521988095715642, -0.04748304933309555, -0.005584154278039932, -0.01912841945886612, -0.02318836748600006, -0.02301083318889141, -0.0322050116956234, 0.005130973644554615, 0.015710288658738136, -0.026600752025842667]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ddf833-8f9a-4986-b1ac-3b3b754846ff",
   "metadata": {},
   "source": [
    "### Vector stores\n",
    "LangChain VectorStore objects contain methods for adding text and Document objects to the store, and querying them using various similarity metrics. They are often initialized with embedding models, which determine how text data is translated to numeric vectors.\n",
    "\n",
    "LangChain includes a suite of integrations with different vector store technologies. Some vector stores are hosted by a provider (e.g., various cloud providers) and require specific credentials to use; some (such as Postgres) run in separate infrastructure that can be run locally or via a third-party; others can run in-memory for lightweight workloads. Let's select a vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75649b66-d1dc-4ffa-82a3-29c37b123865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-chroma in c:\\users\\prath\\miniconda3\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: langchain-core>=0.3.76 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-chroma) (0.3.76)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-chroma) (2.2.6)\n",
      "Requirement already satisfied: chromadb>=1.0.20 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-chroma) (1.1.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (0.37.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.23.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (0.19.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from chromadb>=1.0.20->langchain-chroma) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2025.8.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\prath\\miniconda3\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prath\\miniconda3\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\prath\\miniconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core>=0.3.76->langchain-chroma) (0.4.30)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langchain-core>=0.3.76->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.76->langchain-chroma) (2.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.4.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\prath\\miniconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\prath\\miniconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\prath\\miniconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (6.32.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\prath\\miniconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain-chroma) (0.58b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (0.1.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (2025.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (1.1.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (3.5.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prath\\miniconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee63e446-21d7-4614-9982-4c131846cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53839eb1-3ecd-4407-b860-58fb753d802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b07ac-ccfe-432c-a3a7-1dad28865148",
   "metadata": {},
   "source": [
    "Note that most vector store implementations will allow you to connect to an existing vector store-- e.g., by providing a client, index name, or other information. See the documentation for a specific integration for more detail.\n",
    "\n",
    "Once we've instantiated a VectorStore that contains documents, we can query it. VectorStore includes methods for querying:\n",
    "\n",
    "Synchronously and asynchronously;\n",
    "By string query and by vector;\n",
    "With and without returning similarity scores;\n",
    "By similarity and maximum marginal relevance (to balance similarity with query to diversity in retrieved results).\n",
    "The methods will generally include a list of Document objects in their outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3675625-175b-4c33-956f-433e457d4672",
   "metadata": {},
   "source": [
    "### Usage\n",
    "Embeddings typically represent text as a \"dense\" vector such that texts with similar meanings are geometrically close. This lets us retrieve relevant information just by passing in a question, without knowledge of any specific key-terms used in the document.\n",
    "\n",
    "Return documents based on similarity to a string query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5cf6580-07af-45c5-bcda-2fa303fed55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='our Greater China geography, occupied by employees focused on implementing our wholesale, NIKE Direct and merchandising \n",
      "strategies in the region, among other functions.\n",
      "In the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of \n",
      "which are owned and three of which are leased. Two other distribution centers, one located in Indianapolis, Indiana and one \n",
      "located in Dayton, Tennessee, are leased and operated by third-party logistics providers. One distribution center for Converse is \n",
      "located in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States, some of \n",
      "which are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United \n",
      "States are located in Laakdal, Belgium; Taicang, China; Tomisato, Japan and Icheon, Korea, all of which we own.' metadata={'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'creationdate': '2023-07-20T22:09:22+00:00', 'page_label': '28', 'moddate': '2023-07-26T15:13:52+08:00', 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'total_pages': 106, 'page': 27, 'creator': 'Workiva', 'start_index': 877, 'author': 'anonymous', 'title': 'Nike 2023 Proxy'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"How many distribution centers does Nike have in the US?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc5d3f5d-03fd-44d1-ab16-11b73484473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='PART I\n",
      "ITEM 1. BUSINESS\n",
      "GENERAL\n",
      "NIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \n",
      "\"Annual Report\"), the terms \"we,\" \"us,\" \"our,\" \"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries \n",
      "and affiliates, collectively, unless the context indicates otherwise.\n",
      "Our principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, \n",
      "equipment, accessories and services. NIKE is the largest seller of athletic footwear and apparel in the world. We sell our products \n",
      "through NIKE Direct operations, which are comprised of both NIKE-owned retail stores and sales through our digital platforms \n",
      "(also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales \n",
      "representatives in nearly all countries around the world. We also offer interactive consumer services and experiences through our' metadata={'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'start_index': 0, 'page': 4, 'total_pages': 106, 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'moddate': '2023-07-26T15:13:52+08:00', 'author': 'anonymous', 'title': 'Nike 2023 Proxy', 'creator': 'Workiva', 'creationdate': '2023-07-20T22:09:22+00:00', 'page_label': '5'}\n"
     ]
    }
   ],
   "source": [
    "# Async query:\n",
    "results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6bf32f-78d3-4727-b356-78100b28236b",
   "metadata": {},
   "source": [
    "### Return scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ff9d9b3-1c82-43cd-b5e9-33432a914bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3697006404399872\n",
      "\n",
      "page_content='YEAR ENDED MAY 31,\n",
      "(Dollars in millions) 2023 2022 2021\n",
      "REVENUES\n",
      "North America $ 21,608 $ 18,353 $ 17,179 \n",
      "Europe, Middle East & Africa  13,418  12,479  11,456 \n",
      "Greater China  7,248  7,547  8,290 \n",
      "Asia Pacific & Latin America  6,431  5,955  5,343 \n",
      "Global Brand Divisions  58  102  25 \n",
      "Total NIKE Brand  48,763  44,436  42,293 \n",
      "Converse  2,427  2,346  2,205 \n",
      "Corporate  27  (72)  40 \n",
      "TOTAL NIKE, INC. REVENUES $ 51,217 $ 46,710 $ 44,538 \n",
      "EARNINGS BEFORE INTEREST AND TAXES\n",
      "North America $ 5,454 $ 5,114 $ 5,089 \n",
      "Europe, Middle East & Africa  3,531  3,293  2,435 \n",
      "Greater China  2,283  2,365  3,243 \n",
      "Asia Pacific & Latin America  1,932  1,896  1,530 \n",
      "Global Brand Divisions  (4,841)  (4,262)  (3,656) \n",
      "Converse  676  669  543 \n",
      "Corporate  (2,840)  (2,219)  (2,261) \n",
      "Interest expense (income), net  (6)  205  262 \n",
      "TOTAL NIKE, INC. INCOME BEFORE INCOME TAXES $ 6,201 $ 6,651 $ 6,661 \n",
      "ADDITIONS TO PROPERTY, PLANT AND EQUIPMENT\n",
      "North America $ 283 $ 146 $ 98 \n",
      "Europe, Middle East & Africa  215  197  153' metadata={'creationdate': '2023-07-20T22:09:22+00:00', 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'total_pages': 106, 'page': 89, 'page_label': '90', 'moddate': '2023-07-26T15:13:52+08:00', 'creator': 'Workiva', 'start_index': 0, 'title': 'Nike 2023 Proxy', 'author': 'anonymous'}\n"
     ]
    }
   ],
   "source": [
    "# Note that providers implement different scores; the score here\n",
    "# is a distance metric that varies inversely with similarity.\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4fc9279-52c4-4357-a924-cb8d44c7ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='to-end technology foundation, which we believe will further accelerate our digital transformation. We believe this unified approach \n",
      "will accelerate growth and unlock more efficiency for our business, while driving speed and responsiveness as we serve \n",
      "consumers globally.\n",
      "FINANCIAL HIGHLIGHTS \n",
      "• In fiscal 2023, NIKE, Inc. achieved record Revenues of $51.2 billion, which increased 10% and 16% on a reported and \n",
      "currency-neutral basis, respectively \n",
      "• NIKE Direct revenues grew 14% from $18.7 billion in fiscal 2022 to $21.3 billion in fiscal 2023, and represented \n",
      "approximately 44% of total NIKE Brand revenues for fiscal 2023\n",
      "• Gross margin for the fiscal year decreased 250 basis points to 43.5% primarily driven by higher product costs, higher \n",
      "markdowns and unfavorable changes in foreign currency exchange rates, partially offset by strategic pricing actions\n",
      "• Inventories as of May 31, 2023 were $8.5 billion, flat compared to the prior year, driven by the actions we took throughout' metadata={'start_index': 1663, 'author': 'anonymous', 'moddate': '2023-07-26T15:13:52+08:00', 'title': 'Nike 2023 Proxy', 'creator': 'Workiva', 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'creationdate': '2023-07-20T22:09:22+00:00', 'page': 31, 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'total_pages': 106, 'page_label': '32'}\n"
     ]
    }
   ],
   "source": [
    "# Return documents based on similarity to an embedded query:\n",
    "\n",
    "embedding = embeddings.embed_query(\"How were Nike's margins impacted in 2023?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f313be3-6edf-497a-84b5-1fe38af76db3",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ab006-5f4c-4ee3-ae69-1f0f55e4780d",
   "metadata": {},
   "source": [
    "LangChain VectorStore objects do not subclass Runnable. LangChain Retrievers are Runnables, so they implement a standard set of methods (e.g., synchronous and asynchronous invoke and batch operations). Although we can construct retrievers from vector stores, retrievers can interface with non-vector store sources of data, as well (such as external APIs).\n",
    "\n",
    "We can create a simple version of this ourselves, without subclassing Retriever. If we choose what method we wish to use to retrieve documents, we can create a runnable easily. Below we will build one around the similarity_search method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04d75e36-c935-4f49-bf4f-196105bf5026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='2c6d5bc7-f680-4aca-b045-ec965207120d', metadata={'author': 'anonymous', 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'moddate': '2023-07-26T15:13:52+08:00', 'title': 'Nike 2023 Proxy', 'total_pages': 106, 'start_index': 877, 'creationdate': '2023-07-20T22:09:22+00:00', 'page_label': '28', 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'creator': 'Workiva', 'page': 27}, page_content='our Greater China geography, occupied by employees focused on implementing our wholesale, NIKE Direct and merchandising \\nstrategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of \\nwhich are owned and three of which are leased. Two other distribution centers, one located in Indianapolis, Indiana and one \\nlocated in Dayton, Tennessee, are leased and operated by third-party logistics providers. One distribution center for Converse is \\nlocated in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States, some of \\nwhich are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United \\nStates are located in Laakdal, Belgium; Taicang, China; Tomisato, Japan and Icheon, Korea, all of which we own.')],\n",
       " [Document(id='e21f8a65-1777-427d-847d-b041a56e0832', metadata={'moddate': '2023-07-26T15:13:52+08:00', 'creator': 'Workiva', 'page': 4, 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'total_pages': 106, 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'title': 'Nike 2023 Proxy', 'author': 'anonymous', 'page_label': '5', 'creationdate': '2023-07-20T22:09:22+00:00', 'start_index': 0}, page_content='PART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \\n\"Annual Report\"), the terms \"we,\" \"us,\" \"our,\" \"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries \\nand affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, \\nequipment, accessories and services. NIKE is the largest seller of athletic footwear and apparel in the world. We sell our products \\nthrough NIKE Direct operations, which are comprised of both NIKE-owned retail stores and sales through our digital platforms \\n(also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales \\nrepresentatives in nearly all countries around the world. We also offer interactive consumer services and experiences through our')]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=1)\n",
    "\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f1f58-8738-4821-b5c3-a5af458e5044",
   "metadata": {},
   "source": [
    "Vectorstores implement an as_retriever method that will generate a Retriever, specifically a VectorStoreRetriever. These retrievers include specific search_type and search_kwargs attributes that identify what methods of the underlying vector store to call, and how to parameterize them. For instance, we can replicate the above with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8e6751a-69c0-4c4c-8f18-458652dbd97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='2c6d5bc7-f680-4aca-b045-ec965207120d', metadata={'creator': 'Workiva', 'page': 27, 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016', 'total_pages': 106, 'page_label': '28', 'author': 'anonymous', 'moddate': '2023-07-26T15:13:52+08:00', 'start_index': 877, 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'title': 'Nike 2023 Proxy', 'creationdate': '2023-07-20T22:09:22+00:00'}, page_content='our Greater China geography, occupied by employees focused on implementing our wholesale, NIKE Direct and merchandising \\nstrategies in the region, among other functions.\\nIn the United States, NIKE has eight significant distribution centers. Five are located in or near Memphis, Tennessee, two of \\nwhich are owned and three of which are leased. Two other distribution centers, one located in Indianapolis, Indiana and one \\nlocated in Dayton, Tennessee, are leased and operated by third-party logistics providers. One distribution center for Converse is \\nlocated in Ontario, California, which is leased. NIKE has a number of distribution facilities outside the United States, some of \\nwhich are leased and operated by third-party logistics providers. The most significant distribution facilities outside the United \\nStates are located in Laakdal, Belgium; Taicang, China; Tomisato, Japan and Icheon, Korea, all of which we own.')],\n",
       " [Document(id='e21f8a65-1777-427d-847d-b041a56e0832', metadata={'moddate': '2023-07-26T15:13:52+08:00', 'page_label': '5', 'author': 'anonymous', 'title': 'Nike 2023 Proxy', 'start_index': 0, 'total_pages': 106, 'source': 'D:\\\\Portfolio\\\\Project\\\\Langchain\\\\semantic search engine/Nike-NPS-Combo_Form-10-K_WR.pdf', 'page': 4, 'creator': 'Workiva', 'creationdate': '2023-07-20T22:09:22+00:00', 'producer': 'Wdesk Fidelity Content Translations Version 008.001.016'}, page_content='PART I\\nITEM 1. BUSINESS\\nGENERAL\\nNIKE, Inc. was incorporated in 1967 under the laws of the State of Oregon. As used in this Annual Report on Form 10-K (this \\n\"Annual Report\"), the terms \"we,\" \"us,\" \"our,\" \"NIKE\" and the \"Company\" refer to NIKE, Inc. and its predecessors, subsidiaries \\nand affiliates, collectively, unless the context indicates otherwise.\\nOur principal business activity is the design, development and worldwide marketing and selling of athletic footwear, apparel, \\nequipment, accessories and services. NIKE is the largest seller of athletic footwear and apparel in the world. We sell our products \\nthrough NIKE Direct operations, which are comprised of both NIKE-owned retail stores and sales through our digital platforms \\n(also referred to as \"NIKE Brand Digital\"), to retail accounts and to a mix of independent distributors, licensees and sales \\nrepresentatives in nearly all countries around the world. We also offer interactive consumer services and experiences through our')]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc73816-0944-4fc7-a34b-ad9a8bfbf328",
   "metadata": {},
   "source": [
    "\n",
    "VectorStoreRetriever supports search types of \"similarity\" (default), \"mmr\" (maximum marginal relevance, described above), and \"similarity_score_threshold\". We can use the latter to threshold documents output by the retriever by similarity score.\n",
    "\n",
    "Retrievers can easily be incorporated into more complex applications, such as retrieval-augmented generation (RAG) applications that combine a given question with retrieved context into a prompt for a LLM. To learn more about building such an application, check out the RAG tutorial tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104abd7-f07f-4046-825a-28244c3dde05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
